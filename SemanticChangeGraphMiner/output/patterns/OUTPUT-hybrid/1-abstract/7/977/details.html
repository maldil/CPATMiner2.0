<html><h3>ca078e83147f95ec7df149ef5eea9b6a8424d3bf,memcnn/models/tests/test_memory_saving.py,,test_memory_saving,#,199
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    network.to(device)
    network.train()
    network.zero_grad()
    <a id="change">optim</a> = torch.optim.RMSprop(network.parameters())
    optim.zero_grad()
    mem_start = 0 if not device == &quotcuda&quot else \
        torch.cuda.memory_allocated() / float(1024 ** 2)

    y = network(xx)
    gc.collect()
    mem_after_forward = mem_reporter.collect_stats() / float(1024 ** 2) if not device == &quotcuda&quot else \
        torch.cuda.memory_allocated() / float(1024 ** 2)
    loss = torch.nn.MSELoss()(y, ytarget)
    <a id="change">optim.zero_grad()</a>
    loss.backward()
    <a id="change">optim.step()</a>
    gc.collect()
    &#47&#47 mem_after_backward = mem_reporter.collect_stats() / float(1024 ** 2) if not device == &quotcuda&quot else \
    &#47&#47     torch.cuda.memory_allocated() / float(1024 ** 2)
    gc.enable()</code></pre><h3>After Change</h3><pre><code class='java'>
        network.to(device)
        network.train()
        network.zero_grad()
        <a id="change">optim</a> = torch.optim.RMSprop(network.parameters())
        optim.zero_grad()
        mem_start = 0 if not device == &quotcuda&quot else \
            torch.cuda.memory_allocated() / float(1024 ** 2)

        y = network(xx)
        gc.collect()
        mem_after_forward = mem_reporter.collect_stats() / float(1024 ** 2) if not device == &quotcuda&quot else \
            torch.cuda.memory_allocated() / float(1024 ** 2)
        loss = torch.nn.MSELoss()(y, ytarget)
        <a id="change">optim.zero_grad()</a>
        loss.backward()
        <a id="change">optim.step()</a>
        gc.collect()
        &#47&#47 mem_after_backward = mem_reporter.collect_stats() / float(1024 ** 2) if not device == &quotcuda&quot else \
        &#47&#47     torch.cuda.memory_allocated() / float(1024 ** 2)
        gc.enable()</code></pre><img src="3880072.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 1</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/silvandeleemput/memcnn/commit/ca078e83147f95ec7df149ef5eea9b6a8424d3bf#diff-50345066c3320a30a946b107a01b394bf8b919d2d397c44e62c2db397ae23fcbL239' target='_blank'>Link</a></div><div id='project'> Project Name: silvandeleemput/memcnn</div><div id='commit'> Commit Name: ca078e83147f95ec7df149ef5eea9b6a8424d3bf</div><div id='time'> Time: 2019-12-12</div><div id='author'> Author: silvandeleemput@gmail.com</div><div id='file'> File Name: memcnn/models/tests/test_memory_saving.py</div><div id='class'> Class Name: </div><div id='method'> Method Name: test_memory_saving</div><BR>