<html><h3>373ae159f7ae1cabaf87228d1ae0fb6acd1c6363,ch14/lib/model.py,AgentDDPG,__call__,#AgentDDPG#,131
</h3><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        return None

    def __call__(self, states, agent_states):
        <a id="change">states_v</a> = <a id="change">ptan.agent.float32_preprocessor(states, cuda=self.cuda)</a>
        <a id="change">mu_v</a> = self.net(states_v)
        <a id="change">actions</a> = mu_v.data.cpu().numpy()

        if self.ou_enabled and self.ou_epsilon &gt; 0:
            new_a_states = []
            for a_state, action in zip(agent_states, actions):
                if a_state is None:
                    a_state = np.zeros(shape=action.shape, dtype=np.float32)
                <a id="change">a_state</a> += self.ou_teta * (self.ou_mu - a_state)
                a_state += self.ou_sigma * np.random.normal(size=action.shape)

                action += self.ou_epsilon * a_state</code></pre><h3>After Change</h3><pre><code class='java'>
        return None

    def __call__(self, states, agent_states):
        <a id="change">states_v</a> = <a id="change">ptan.agent.float32_preprocessor(states).to(self.device)</a>
        <a id="change">mu_v</a> = self.net(states_v)
        <a id="change">actions</a> = mu_v.data.cpu().numpy()

        if self.ou_enabled and self.ou_epsilon &gt; 0:
            new_a_states = []
            for a_state, action in zip(agent_states, actions):
                if a_state is None:
                    a_state = np.zeros(shape=action.shape, dtype=np.float32)
                <a id="change">a_state</a> += self.ou_teta * (self.ou_mu - a_state)
                a_state += self.ou_sigma * np.random.normal(size=action.shape)

                action += self.ou_epsilon * a_state</code></pre><img src="3880383.png" alt="Italian Trulli"   style="width:500px;height:500px;"><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 1</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/commit/373ae159f7ae1cabaf87228d1ae0fb6acd1c6363#diff-9333e01a0bf66b432bc83caf4acc141ac96ee89e02e8528caf7d121c5c9de62aL132' target='_blank'>Link</a></div><div id='project'> Project Name: PacktPublishing/Deep-Reinforcement-Learning-Hands-On</div><div id='commit'> Commit Name: 373ae159f7ae1cabaf87228d1ae0fb6acd1c6363</div><div id='time'> Time: 2018-04-29</div><div id='author'> Author: max.lapan@gmail.com</div><div id='file'> File Name: ch14/lib/model.py</div><div id='class'> Class Name: AgentDDPG</div><div id='method'> Method Name: __call__</div><BR>