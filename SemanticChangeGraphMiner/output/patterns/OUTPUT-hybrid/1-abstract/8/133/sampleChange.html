<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3>9efd811508afbbcbb7357735b6b5ed10166cd084,deeplearning4j/deeplearning4j-core/src/test/java/org/deeplearning4j/nn/layers/samediff/TestSameDiffLambda.java,TestSameDiffLambda,testSameDiffLamdaLayerBasic,#,54
</h3><h3>Before Change</h3><pre><code class='java'>
                .graphBuilder()
                .addInputs("in")
                .addLayer("0", new DenseLayer.Builder().nIn(5).nOut(5).activation(Activation.TANH).build(), "in")
                .<a id="change">addLayer(</a>"1", new SameDiffSimpleLambdaLayer(), "0"<a id="change">)</a>
                .addLayer("2", new OutputLayer.Builder().nIn(5).nOut(5).activation(Activation.SOFTMAX)
                        .lossFunction(LossFunctions.LossFunction.MCXENT).<a id="change">build()</a>, "1")
                .setOutputs("2")
                .build();
</code></pre><h3>After Change</h3><pre><code class='java'>

    @Test
    public void testSameDiffLamdaLayerBasic(){
        <a id="change">for(</a>WorkspaceMode wsm : new WorkspaceMode[]{WorkspaceMode.ENABLED, WorkspaceMode.NONE}<a id="change">) </a>{
            log.info("--- Workspace Mode: {} ---", wsm);


            Nd4j.getRandom().setSeed(12345);
            ComputationGraphConfiguration conf = new NeuralNetConfiguration.Builder()
                    .trainingWorkspaceMode(wsm)
                    .<a id="change">inferenceWorkspaceMode(wsm</a><a id="change">)</a>
                    .seed(12345)
                    .updater(new Adam(0.01))
                    .graphBuilder()
                    .addInputs("in")
                    .addLayer("0", new DenseLayer.Builder().nIn(5).nOut(5).activation(Activation.TANH).build(), "in")
                    .<a id="change">addLayer(</a>"1", new SameDiffSimpleLambdaLayer(), "0"<a id="change">)</a>
                    .addLayer("2", new OutputLayer.Builder().nIn(5).nOut(5).activation(Activation.SOFTMAX)
                            .lossFunction(LossFunctions.LossFunction.MCXENT).build(), "1")
                    .setOutputs("2")
                    .build();

            //Equavalent, not using SameDiff Lambda:
            ComputationGraphConfiguration confStd = new NeuralNetConfiguration.Builder()
                    .<a id="change">trainingWorkspaceMode(wsm</a><a id="change">)</a>
                    .inferenceWorkspaceMode(wsm)
                    .seed(12345)
                    .updater(new Adam(0.01))
                    .graphBuilder()
                    .addInputs("in")
                    .addLayer("0", new DenseLayer.Builder().nIn(5).nOut(5).activation(Activation.TANH).build(), "in")
                    .addVertex("1", new ShiftVertex(1.0), "0")
                    .addVertex("2", new ScaleVertex(2.0), "1")
                    .addLayer("3", new OutputLayer.Builder().nIn(5).nOut(5).activation(Activation.SOFTMAX)
                            .lossFunction(LossFunctions.LossFunction.MCXENT).<a id="change">build()</a>, "2")
                    .setOutputs("3")
                    .build();
</code></pre>